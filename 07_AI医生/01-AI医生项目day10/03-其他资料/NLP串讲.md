- 问题1: NLP + CV 最大的两块现实应用是

  - 1: 拍图说说
    - ![拍图翻译](/Users/zhudejun/Desktop/2020-05-09 -- 直播课/拍图翻译.png)
  - 2: 看图说话 (image caption)
    - ![4914AA0140FB464EC9DF6F4D2A53D8FA](/Users/zhudejun/Desktop/2020-05-09 -- 直播课/4914AA0140FB464EC9DF6F4D2A53D8FA.png)
  - 核心: 先用CNN将图片提取成一个特征张量, 再用RNN对这个张量进行解码, 本质上也是seq2seq架构。

- 问题2: 

  - 单一的项目, 看规模, 但是大部分介于2-3个小团队到15-20人大团队。
  - 按照个人擅长的分工, 短则1-2周, 长则6-12个月。

- 问题3: 

  - 传智的课程本身就是按照1-2年左右工作经验来设计的。
  - 20-30K这个区间是完全没问题的!!!

- 问题4: 

  - 1: 串讲Bert的时候已经提到了很多细节。
  - 2: 关于特征提取器的差异
    - 2.1: ELmo采用双向LSTM提取
    - 2.2: Bert采用双向Transformer提取
    - 2.3: GPT采用单向Transformer提取
  - 3: 关于语言模型的差异
    - 3.1: ELmo采用双向语言模型, 可以同时采集前后语义的关系和含义
    - 3.2: Bert采用双向语言模型, 相当于只用了Transformer中的Encoder, 可以看见完整的句子, 是三者中提取特征能力最强大的
    - 3.3: GPT采用单向语言模型, 相当于只用了Transformer中的Decoder, 看不见完整的句子, 特征采集能力不如Bert

- 问题5: 

  - 知识图谱是NLP一个单独的细分领域, 需要专门做, 比较窄, 除非特别有兴趣专攻, 不然不建议押注这个领域。Neo4j就是主要针对知识图谱的。

  - 词义消歧, 语义消歧: 

    - ```
      雷军对小米有特别的感情。
      那家店卖的小米特别棒。
      我昨天刚买了一个苹果。
      ```

    - 1: 基于词典的语义消歧

    - 2: 有监督的深度学习语义消歧 (类似于词性标注, NER任务)

    - 3: 无监督 (但是依赖于在一个大规模语料库上的句法分析结果)

    - 4: https://www.bbsmax.com/A/E35pl6QE5v/

  - 句向量: 

    - 1: 词的叠加
    - 2: Bert (Transformer)

  - 文档向量: 

    - 1: LDA (文档主题模型)
    - 2: Bert

- 问题6: 

  - 1: 如果你的BOSS, 你来定。
  - 2: 如果你是架构师, 你来定, 同时给出原因。
  - 3: 如果你是刚入行的工程师, 听话干活。
  - 4: 这里面从公司的角度来说, 性价比很低, 大家可以加工简历, 这个当做一个探索项目 or 案例学习项目 (代表你有深厚的理论基础)。